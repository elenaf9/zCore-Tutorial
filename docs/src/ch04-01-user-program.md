# Zircon User Program

## User state startup process

### Process overview
 kernel   
 -> userboot (decompress bootsvc LZ4 format)   
 -> bootsvc (executable bin/component_manager)  
 -> component_manager   
 -> sh / device_manager  

### ZBI (Zircon Boot Image)
ZBI is a simple container format that embeds a number of items that can be passed by the boot loader `BootLoader`, including hardware-specific information, a kernel `command line` that provides boot options, and a RAM disk image (usually compressed). The `ZBI` contains the initial file system `bootfs`, which the kernel passes in its entirety to `userboot`, which is responsible for parsing and serving files to other processes.


### bootfs

The basic `bootfs` image satisfies all the dependencies needed to run a user-space program.
+ executable files
+ shared libraries
+ data files  
  
The above list also enables device drivers or more advanced file systems that can access and read more code and data from storage or network devices.

At the end of system self-boot, the files in `bootfs` become a read-only file system tree mounted on the root directory `/boot` (and served by bootsvc). Subsequently `userboot` will load the first real user program from `bootfs`.

### [zCore program (ELF loading with dynamic linking)](https://fuchsia.dev/fuchsia-src/concepts/booting/program_loading)

The zCore kernel is not directly involved in the loading of normal programs, but provides some modules that are available when loading user state programs. Such as virtual memory objects (VMOs), processes, virtual address spaces (VMARs) and threads. 


### ELF format and system application binary interface (system ABI)


The standard zCore user space environment provides a dynamic linker and an ELF-based execution environment capable of running ELF formatted machine code executables. zCore processes can only use system calls through the zCore vDSO. The kernel provides vDSO using the program binary interface (ABI) common to ELF-based systems.  

User space code with appropriate functionality can create processes and load programs directly via system calls without using ELF. but the standard ABI for zCore uses ELF as described here. background on the ELF file format is as follows: 

### ELF file types 

"ET_REL" means that this ELF file is a relocatable file  

"ET_EXEC" means that the ELF file is an executable file  
 
"ET_DYN" means that the ELF file is a dynamic link library  

"ET_CORE" means the ELF file is a core dump file  


### Traditional ELF program file loading  

The Executable and Linking Format (ELF) was originally developed and released by the UNIX System Lab and has become the common standard executable file format for most Unix-like systems. On these systems, the kernel uses the ``POSIX`` (Portable Operating System Interface) ``execve API`` to integrate program loading with file system access. The way ELF programs are loaded on such systems varies somewhat, but most follow the following pattern.  


1. the kernel loads the file by name and checks whether it is an ELF or some other type of file supported by the system.  


2. The kernel maps the ELF image according to the ``PT_LOAD`` program header of the ELF file. For ``ET_EXEC`` files, the system places the sections (Sections) of the program at fixed addresses in memory specified in ``p_vaddr``. For ``ET_DYN`` files, the system loads the base address of the first ``PT_LOAD`` of the program and then places subsequent sections according to their ``p_vaddr`` relative to the ``p_vaddr`` of the first section. Typically this base address is generated by address randomization (ASLR) 3.  


If the ELF file has a ``PT_INTERP`` (Program interpreter) program header, part of its contents (some bytes given by ``p_offset`` and ``p_filesz`` in the ELF file) is used as a filename to find another file called "ELF interpreter". Such an ELF file as described above is an ``ET_DYN`` file. The kernel loads this type of ELF file in the same way, but the address loaded is self-defined. This ELF "interpreter" usually refers to the ELF dynamic linker named ``/lib/ld.so.1`` or ``/lib/ld-linux.so.2``. 4.

4. The kernel sets the contents of the registers and stack for the initial thread and starts the thread if the PC registers already point to a specific program entry point (Entry Point). 
    + The entry point is the value of ``e_entry`` in the ELF file header, which is adjusted according to the program base address. If this is an ELF file with ``PT_INTERP``, then its entry point is not in itself, but is set in the dynamic linker.
    + The kernel sets registers and stacks to enable the program to receive specific parameters, environment variables, and other auxiliary vectors that have practical use. The way registers and stacks are set follows an assembly-level protocol approach. If the ELF file runs with dynamic linking, i.e., with ``PT_INTERP``, then the registers and stack will include the data from the program. then the registers and stack will include base address, entry point, and program header table address information from the ELF file header of that executable that allows the dynamic linker to find the ELF dynamic linking metadata for that executable in memory for dynamic linking. When dynamic linking is initiated, the dynamic linker will jump to the entry point address of that executable.

```rust
    pub fn sys_process_start(
        &self,
        proc_handle: HandleValue,
        thread_handle: HandleValue,
        entry: usize,
        stack: usize,
        arg1_handle: HandleValue,
        arg2: usize,
    ) -> ZxResult {
        info!("process.start: proc_handle={:?}, thread_handle={:?}, entry={:?}, stack={:?}, arg1_handle={:?}, arg2={:?}",
            proc_handle, thread_handle, entry, stack, arg1_handle, arg2
        );
        let proc = self.thread.proc();
        let process = proc.get_object_with_rights::<Process>(proc_handle, Rights::WRITE)?;
        let thread = proc.get_object_with_rights::<Thread>(thread_handle, Rights::WRITE)?;
        if !Arc::ptr_eq(&thread.proc(), &process) {
            return Err(ZxError::ACCESS_DENIED);
        }
        let arg1 = if arg1_handle != INVALID_HANDLE {
            let arg1 = proc.remove_handle(arg1_handle)?;
            if !arg1.rights.contains(Rights::TRANSFER) {
                return Err(ZxError::ACCESS_DENIED);
            }
            Some(arg1)
        } else {
            None
        };
        process.start(&thread, entry, stack, arg1, arg2, self.spawn_fn)?;
        Ok(())
    }
```zCore's program loading is inspired by the traditional approach, but with some differences. In the traditional model, a key reason for needing to load an executable before loading the dynamic linker is that the base address chosen randomly by the dynamic linker cannot intersect with the fixed address used by the ```ET_EXEC`` executable. zCore does not fundamentally support fixed-address program loading for ``ET_EXEC`` format ELF files. address program load, it only supports location-independent executables or [PIE](https://patchwork.kernel.org/patch/9807325/) (```ET_DYN`` format ELF files)


### VmarExt trait implementation 

The underlying zCore API does not support a file system. zCore program files are loaded via Virtual Memory Objects (VMOs) and the inter-process communication mechanism used by ``channel``.

The loading of programs is based on some premises as follows:
+ Getting a handle to a virtual memory object (VMO) containing the executable file.

> zircon-object\src\util\elf_loader.rs
```shell
fn make_vmo(elf: &ElfFile, ph: ProgramHeader) -> ZxResult<Arc<VmObject>> {
    assert_eq!(ph.get_type().unwrap(), Type::Load).
    let page_offset = ph.virtual_addr() as usize % PAGE_SIZE.
    let pages = pages(ph.mem_size() as usize + page_offset).
    let vmo = VmObject::new_paged(pages).
    let data = match ph.get_data(&elf).unwrap() {
        SegmentData::Undefined(data) => data.
        _ => return Err(ZxError::INVALID_ARGS).
    }.
    vmo.write(page_offset, data)? .
    Ok(vmo)
}
```
+ The list of program execution parameters.
+ A list of program execution environment variables.
+ An initial list of handles exists, each with a handle information item.


### USERBOOT

#### Reasons for using userboot 

In Zircon, the `RAM disk image` embedded in ZBI is usually compressed using the [LZ4](https://github.com/lz4/lz4) format. After decompression you will continue to get a disk image in `bootfs` format. This is a simple read-only file system format, which lists only the file names. For each file, its offset and size in the BOOTFS image can be listed separately (both values must be page-aligned and limited to 32 bits).

Since the kernel does not contain any code that can be used to decompress the [LZ4](https://github.com/lz4/lz4) format, there is also no code for parsing the BOOTFS format. All this work is done by the first user space process called `userboot`.


> The relevant implementation for decompressing bootfs was not found in zCore.  
> but it can be found in scripts/gen-prebuilt.sh that does have bootfs in ZBI  
> and the existing zCore implementation of the loaded ZBI is as follows:  

> zircon-loader/src/lib.rs
```rust
    // zbi
    let zbi_vmo = {
        let vmo = VmObject::new_paged(images.zbi.as_ref().len() / PAGE_SIZE + 1).
        vmo.write(0, images.zbi.as_ref()).unwrap().
        vmo.set_name("zbi").
        vmo
    }.
```
#### what is userboot
userboot is a normal userspace process. It can only execute standard system calls via vDSO like any other process, and is subject to the full vDSO execution regime.

> The only user process created "unconventionally" by the kernel state   
> 
> userboot specifically does the following:  
> 
> + read cmdlines, handles from channels 
> 
> + parse zbi
> 
> + decompress BOOTFS 
> 
> + select the next program to start act as a loader yourself and "die"  
> 
> + Start the next program in the "normal way"


userboot is built as an ELF dynamic shared object (DSO, dynamic shared object), using the same layout as vDSO. Like vDSO, userboot's ELF image is embedded in the kernel at compile time. Its simple layout means that loading it does not require the kernel to parse the ELF file headers at boot time. The kernel only needs to know three things.
1. the size of the read-only segment `segment
2. the size of the executable segment `segment
3. the address of the `userboot` entry point.  
   
These values can be extracted from the userboot ELF image at compile time and used as constants in the kernel code.

How the #### kernel enables userboot

Like any other process, userboot must start from a vDSO that has been mapped to its address space so that it can make system calls. The kernel maps userboot and vDSO to the first user process, and then starts it at the entry point of userboot.

<! -- > !  The special thing about userboot is the way it is loaded.   
> ... .todo -->

#### How userboot gets system calls in vDSO
When the kernel maps `userboot` to the first user process, it chooses a random address in memory to load, just like a normal program would. When mapping `userboot`'s vDSO, instead of using the random approach described above, the vDSO image is placed in memory directly after `userboot`'s image. In this way, the offset of the vDSO code from `userboot` is always fixed.

During the compilation phase, the entry point symbol table for the system calls is extracted from the vDSO ELF image and subsequently written to the symbol definition of the link script. Using the relatively fixed offset address of each symbol in the vDSO image, the symbol can be defined at a fixed offset from the `_end` symbol provided by the link script. In this way, the userboot code can directly call the vDSO entry point at each exact location in memory, after the image itself.

Related code:
> zircon-loader/src/lib.rs
```rust
pub fn run_userboot(images: &Images<impl AsRef<[u8]>>, cmdline: &str) -> Arc<Process> {
    ...
    // vdso
    let vdso_vmo = {
        let elf = ElfFile::new(images.vdso.as_ref()).unwrap();
        let vdso_vmo = VmObject::new_paged(images.vdso.as_ref().len() / PAGE_SIZE + 1);
        vdso_vmo.write(0, images.vdso.as_ref()).unwrap();
        let size = elf.load_segment_size();
        let vmar = vmar
            .allocate_at(
                userboot_size,
                size,
                VmarFlags::CAN_MAP_RXW | VmarFlags::SPECIFIC,
                PAGE_SIZE,
            )
            .unwrap();
        vmar.map_from_elf(&elf, vdso_vmo.clone()).unwrap();
        #[cfg(feature = "std")]
        {
            let offset = elf
                .get_symbol_address("zcore_syscall_entry")
                .expect("failed to locate syscall entry") as usize;
            let syscall_entry = &(kernel_hal_unix::syscall_entry as usize).to_ne_bytes();
            // fill syscall entry x3
            vdso_vmo.write(offset, syscall_entry).unwrap();
            vdso_vmo.write(offset + 8, syscall_entry).unwrap();
            vdso_vmo.write(offset + 16, syscall_entry).unwrap();
        }
        vdso_vmo
    };
    ...

}
```
### bootsvc
bootsvc is usually the first program loaded by usermode (unlike userboot, which is loaded by the kernel). bootsvc provides several system services:
+ file system services containing the contents of bootfs (/boot) (the initial bootfs image contains everything the userspace system needs to run.
  - Executable files
  - Shared libraries and data files (including device drivers or more advanced file system implementations)
+ loader services loaded from bootfs

 
+ bin/component_manager  
+ sh / device_manager    






## Composition of the user program

> Kernel is not directly involved in loading the user program (except for the first process)
>
> User programs force PIC and PIE (location independent code)
>
> Memory address space composition: Program, Stack, vDSO, Dylibs
>
> Passing startup information and handles via Channel











## Springboard for system calls: vDSO

#### Introducing the role of vDSO

vDSO (virtual Dynamic Shared Object), Zircon vDSO is the only way for the Zircon kernel to access system calls (as a springboard for system calls). It is virtual because it is not loaded from an ELF file in the filesystem, but is a vDSO image provided directly by the kernel.

<! -- Zircon vDSO is the only means of accessing the Zircon system calls. vDSO represents a virtual dynamic shared object. (Dynamic Shared Object is a term used for shared libraries in ELF format.) It is virtual because it is not loaded from an ELF file in the file system. Instead, the vDSO image is provided directly by the kernel. -->

> zCore/src/main.rs
```rust
#[cfg(feature = "zircon")]
fn main(ramfs_data: &[u8], cmdline: &str) {
    use zircon_loader::{run_userboot, Images}.
    let images = Images::<&[u8]> {
        userboot: include_bytes!(". /... /prebuilt/zircon/x64/userboot.so").
        vdso: include_bytes!("... /... /prebuilt/zircon/x64/libzircon.so").
        zbi: ramfs_data.
    }.
    let _proc = run_userboot(&images, cmdline).
    run().
}
```

It is a user-state run code that is wrapped into the `prebuilt/zircon/x64/libzircon.so` file. This .so file load is not placed in the filesystem, but is provided by the kernel. It is integrated in the kernel image.

The vDSO image is embedded in the kernel at compile time. The kernel exposes it to user space as a read-only VMO. The kernel gets the physical page it is on by calculation when it starts. When the `program loader` sets up a new process, the only way to enable that process to make system calls is for the `program loader` to map the vDSO to the virtual address space (address randomization) of the new process before the first thread of the new process starts running. Therefore, each process itself must be able to access the vDSO's VMO before starting other processes that can make system calls.

> zircon-loader/src/lib.rs#line167  

```rust
    proc.start(&thread, entry, sp, Some(handle), 0, thread_fn)
        .expect("failed to start main thread").
    proc
```
> zircon-object/src/task/process.rs#line189  

```rust
    thread.start(entry, stack, handle_value as usize, arg2, thread_fn)
```

The vDSO is mapped to the new process while passing the `base address` of the image to the first thread in the new process via the `arg2` argument. With this address, the ELF file header can be found in memory, which points to other ELF program modules that can be used to find system call symbolic names.

#### How to modify the vDSO source code (libzircon) to change syscall to a function call

##### Related code
+ Reference repository [README.MD](https://github.com/PanQL/zircon/blob/master/README.md)
    > --- The compile_commands.json for parsing code dependencies will be generated with the build process to the **out** folder ---

##### How to generate imgs(VDSO,ZBI)
1. clone Zircon code repository (the zircon code separated from the official fuchsia directory)
    ```shell  
    $ git clone https://github.com/PanQL/zircon.git
    ```
2. About compiling and running Zircon  
In order to reduce the size of the repository, we have significantly adjusted the prebuilt directory; therefore, before running, please download the google prebuilt clang, unzip it and put it in a location with the right permissions, and then add it to the code in [this location](https://github.com/PanQL/zircon/blob/master/) public/gn/toolchain/clang.gni#L16) and change the **absolute directory** to the corresponding location. 
   clang download link.
   * [cloud download link](https://cloud.tsinghua.edu.cn/d/7ab1d87feecd4b2cb3d8/)  
   * The official CIPD package download link is as follows  
       * [Linux](https://chrome-infra-packages.appspot.com/p/fuchsia/clang/linux-amd64/+/oEsFSe99FkcDKVxZkAY0MKi6C-yYOan1m-QL45N33W8C)  
       * [Mac](https://chrome-infra-packages.appspot.com/p/fuchsia/clang/mac-amd64/+/Lc64-GTi4kihzkCnW8Vaa80TWTnMpZY0Fy6AqChmqvcC)    


3. Currently, compilation is only supported on Mac OS and Linux x64.  
The default `make run` and `make build` are for x64 architecture, if you wish to compile and run zircon for arm architecture, then you need to:
  * Change `legacy-image-x64` to `legacy-image-arm64` in out/args.gn  
   * Re`make build`  
   * `make runarm`  

   



4. Work with the relevant scripts and patch files in zCore
    - scripts/gen-prebuilt.sh
    - scripts/zircon-libos.patch
   + https://github.com/PanQL/zircon/blob/master/system/ulib/zircon/syscall-entry.h
   + https://github.com/PanQL/zircon/blob/master/system/ulib/zircon/syscalls-x86-64.S
   + zircon-loader/src/lib.rs#line 83-93
```rust
        #[cfg(feature = "std")]
        {
            let offset = elf
                .get_symbol_address("zcore_syscall_entry")
                .expect("failed to locate syscall entry") as usize.
            let syscall_entry = &(kernel_hal_unix::syscall_entry as usize).to_ne_bytes().
            // fill syscall entry x3
            vdso_vmo.write(offset, syscall_entry).unwrap().
            vdso_vmo.write(offset + 8, syscall_entry).unwrap().
            vdso_vmo.write(offset + 16, syscall_entry).unwrap().
        }

```

<! -- When vsdo uses the svc instruction, this is when the CPU exception goes into the kernel to the sync_exception macro in expectations.S (the sync_exception argument is different for different ELx). Then this sync_exception macro does some field saving work and then jumps to the arm64_syscall_dispatcher macro.

After entering the arm64_syscall_dispatcher macro, first do some syscall number checking, then the syscall number jumps to the function of the corresponding index item in the call_wrapper_table function table (call_wrapper_table is like a one-dimensional function pointer array, syscall number jumps to the function of the corresponding index item in the call_wrapper_table function table). (call_wrapper_table is like a one-dimensional array of function pointers, syscall number makes the index and jumps to the corresponding wrapper syscall function function). -->

#### Modify the vDSO snippet when loading vDSO, fill in the jump address
## First user program: userboot

> Implement the run_userboot function in zircon-loader
> 
> to be able to enter the user state and jump back on the first system call


#### loads the first real user program from `bootfs`.
The main relevant code:
> zircon-loader/src/lib.rs
> zircon-object/src/util/elf_loader.rs

When `userboot` finishes unpacking the `bootfs` in `ZBI`, `userboot` will continue to load the program files from the `bootfs` and run them.

The specific implementation process in Zircon is as follows:
1. `userboot` checks the environment strings received from the kernel, which represent certain kernel command lines.
    > zircon-loader/src/main.rs
    ```rust
    #[async_std::main]
    async fn main() {
        kernel_hal_unix::init().
        init_logger().

        let opt = Opt::from_args().
        let images = open_images(&opt.prebuilt_path).expect("failed to read file").

        let proc: Arc<dyn KernelObject> = run_userboot(&images, &opt.cmdline).
        drop(images).

        proc.wait_signal(Signal::USER_SIGNAL_0).await.
    }
    ```

   In Zircon:
   + If the string reads ``userboot=file``, then the `file` will be loaded as the first real user process.
   + If there is no such option, then the default text that `userboot` will choose is `bin/bootsvc`. This file can be found in `bootfs`.
  
   And in the zCore implementation:
   + ...
2. To load the above files, userboot implements a fully functional ELF program loader
   `zircon_object::util::elf_loader::load_from_elf`
    ```rust
        // userboot
        let (entry, userboot_size) = {
            let elf = ElfFile::new(images.userboot.as_ref()).unwrap().
            let size = elf.load_segment_size().
            let vmar = vmar
                .allocate(None, size, VmarFlags::CAN_MAP_RXW, PAGE_SIZE)
                .unwrap().
            vmar.load_from_elf(&elf).unwrap().
            (vmar.addr() + elf.header.pt2.entry_point() as usize, size)
        }.
    ```
3. userboot then loads the vDSO with a random address. it starts the new process using the standard convention and passes it a channel handle and the vDSO base address.
   `zircon_object::util::elf_loader::map_from_elf`
